{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# import all csv's from a folder and combine them into one dataframe\n",
    "def combine_data_files(folder_path):\n",
    "    df_list = []\n",
    "\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.csv'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            df = pd.read_csv(file_path)\n",
    "            df_list.append(df)\n",
    "\n",
    "    return pd.concat(df_list, axis=0, ignore_index=True)\n",
    "\n",
    "# Once data is imported from csv to a dataframe, clean up the datatypes\n",
    "def clean_df_new(df):\n",
    "    \n",
    "    resMap = lambda res : 'White' if res == '1-0' else 'Black' if res == '0-1' else 'Draw' if res == \"1/2-1/2\" else res\n",
    "    cleanDateTime = lambda d: pd.to_datetime(d)\n",
    "    cleanComment = lambda x: x if x.find(']') == -1 else x.split(\"] \")[1]\n",
    "\n",
    "    datetime_columns = ['Date', 'Time', 'WhiteClock', 'BlackClock']\n",
    "    float_columns = ['WhiteRD', 'BlackRD', 'AvgEvalOpening', 'AvgEvalMiddle', 'AvgEvalEnd', 'AvgEmtOpening', 'AvgEmtMiddle', 'AvgEmtEnd']\n",
    "    int_columns = ['FICSGamesDBGameNo', 'WhiteElo', 'BlackElo', 'PlyCount']\n",
    "\n",
    "    df = df.drop(['Event', 'Site', 'Round', 'WhiteClock', 'BlackClock'], axis=1)\n",
    "\n",
    "    for column in df.columns:\n",
    "\n",
    "        if column in float_columns:\n",
    "            df[column] = df[column].astype(float)\n",
    "        elif column in int_columns:\n",
    "            df[column] = df[column].astype(int)\n",
    "        elif column in datetime_columns:\n",
    "            df[column] = df[column].apply(cleanDateTime)\n",
    "        else:\n",
    "            if column == 'Result':\n",
    "                df[column] = df[column].apply(resMap)\n",
    "            if column == 'ResultComment':\n",
    "                df[column] = df[column].apply(cleanComment)\n",
    "            df[column] = df[column].astype('category')\n",
    "\n",
    "    df['WhiteIsComp'] = df['WhiteIsComp'] == 'Yes'\n",
    "    df['BlackIsComp'] = df['BlackIsComp'] == 'Yes'\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date                 datetime64[ns]\n",
      "White                      category\n",
      "Black                      category\n",
      "Result                     category\n",
      "BlackElo                      int64\n",
      "BlackIsComp                    bool\n",
      "BlackRD                     float64\n",
      "ECO                        category\n",
      "FICSGamesDBGameNo             int64\n",
      "PlyCount                      int64\n",
      "Time                 datetime64[ns]\n",
      "TimeControl                category\n",
      "WhiteElo                      int64\n",
      "WhiteIsComp                    bool\n",
      "WhiteRD                     float64\n",
      "AvgEvalOpening              float64\n",
      "AvgEvalMiddle               float64\n",
      "AvgEvalEnd                  float64\n",
      "AvgEmtOpening               float64\n",
      "AvgEmtMiddle                float64\n",
      "AvgEmtEnd                   float64\n",
      "ResultComment              category\n",
      "dtype: object\n",
      "(25884, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>White</th>\n",
       "      <th>Black</th>\n",
       "      <th>Result</th>\n",
       "      <th>BlackElo</th>\n",
       "      <th>BlackIsComp</th>\n",
       "      <th>BlackRD</th>\n",
       "      <th>ECO</th>\n",
       "      <th>FICSGamesDBGameNo</th>\n",
       "      <th>PlyCount</th>\n",
       "      <th>...</th>\n",
       "      <th>WhiteElo</th>\n",
       "      <th>WhiteIsComp</th>\n",
       "      <th>WhiteRD</th>\n",
       "      <th>AvgEvalOpening</th>\n",
       "      <th>AvgEvalMiddle</th>\n",
       "      <th>AvgEvalEnd</th>\n",
       "      <th>AvgEmtOpening</th>\n",
       "      <th>AvgEmtMiddle</th>\n",
       "      <th>AvgEmtEnd</th>\n",
       "      <th>ResultComment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>ArasanX</td>\n",
       "      <td>Notarious</td>\n",
       "      <td>Draw</td>\n",
       "      <td>2874</td>\n",
       "      <td>True</td>\n",
       "      <td>37.2</td>\n",
       "      <td>B10</td>\n",
       "      <td>530376668</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>2780</td>\n",
       "      <td>True</td>\n",
       "      <td>34.7</td>\n",
       "      <td>15.571429</td>\n",
       "      <td>-7.461538</td>\n",
       "      <td>5.416667</td>\n",
       "      <td>0.126308</td>\n",
       "      <td>3.120000</td>\n",
       "      <td>3.252667</td>\n",
       "      <td>Game drawn by mutual agreement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>Notarious</td>\n",
       "      <td>ArasanX</td>\n",
       "      <td>White</td>\n",
       "      <td>2786</td>\n",
       "      <td>True</td>\n",
       "      <td>34.8</td>\n",
       "      <td>D79</td>\n",
       "      <td>530376382</td>\n",
       "      <td>139</td>\n",
       "      <td>...</td>\n",
       "      <td>2868</td>\n",
       "      <td>True</td>\n",
       "      <td>37.4</td>\n",
       "      <td>30.340426</td>\n",
       "      <td>46.913043</td>\n",
       "      <td>104.086957</td>\n",
       "      <td>2.313957</td>\n",
       "      <td>3.352826</td>\n",
       "      <td>0.753348</td>\n",
       "      <td>Black resigns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>exeComp</td>\n",
       "      <td>ArasanX</td>\n",
       "      <td>Black</td>\n",
       "      <td>2780</td>\n",
       "      <td>True</td>\n",
       "      <td>34.9</td>\n",
       "      <td>A17</td>\n",
       "      <td>530375680</td>\n",
       "      <td>274</td>\n",
       "      <td>...</td>\n",
       "      <td>2711</td>\n",
       "      <td>True</td>\n",
       "      <td>37.9</td>\n",
       "      <td>59.739130</td>\n",
       "      <td>58.186813</td>\n",
       "      <td>-216.551724</td>\n",
       "      <td>3.552725</td>\n",
       "      <td>0.891088</td>\n",
       "      <td>0.430033</td>\n",
       "      <td>White resigns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>nthmaster</td>\n",
       "      <td>Speyside</td>\n",
       "      <td>White</td>\n",
       "      <td>2202</td>\n",
       "      <td>True</td>\n",
       "      <td>45.1</td>\n",
       "      <td>D27</td>\n",
       "      <td>530375325</td>\n",
       "      <td>169</td>\n",
       "      <td>...</td>\n",
       "      <td>2135</td>\n",
       "      <td>False</td>\n",
       "      <td>40.3</td>\n",
       "      <td>201.561404</td>\n",
       "      <td>500.696429</td>\n",
       "      <td>991.975610</td>\n",
       "      <td>2.761375</td>\n",
       "      <td>1.995554</td>\n",
       "      <td>0.277589</td>\n",
       "      <td>Black checkmated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>GriffyJr</td>\n",
       "      <td>family</td>\n",
       "      <td>Black</td>\n",
       "      <td>2019</td>\n",
       "      <td>False</td>\n",
       "      <td>48.5</td>\n",
       "      <td>C01</td>\n",
       "      <td>530374794</td>\n",
       "      <td>162</td>\n",
       "      <td>...</td>\n",
       "      <td>2028</td>\n",
       "      <td>True</td>\n",
       "      <td>37.3</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>-108.166667</td>\n",
       "      <td>-410.115385</td>\n",
       "      <td>0.609074</td>\n",
       "      <td>0.589000</td>\n",
       "      <td>0.436094</td>\n",
       "      <td>White resigns</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date      White      Black Result  BlackElo  BlackIsComp  BlackRD  \\\n",
       "0 2023-02-28    ArasanX  Notarious   Draw      2874         True     37.2   \n",
       "1 2023-02-28  Notarious    ArasanX  White      2786         True     34.8   \n",
       "2 2023-02-28    exeComp    ArasanX  Black      2780         True     34.9   \n",
       "3 2023-02-28  nthmaster   Speyside  White      2202         True     45.1   \n",
       "4 2023-02-28   GriffyJr     family  Black      2019        False     48.5   \n",
       "\n",
       "   ECO  FICSGamesDBGameNo  PlyCount  ... WhiteElo WhiteIsComp  WhiteRD  \\\n",
       "0  B10          530376668        39  ...     2780        True     34.7   \n",
       "1  D79          530376382       139  ...     2868        True     37.4   \n",
       "2  A17          530375680       274  ...     2711        True     37.9   \n",
       "3  D27          530375325       169  ...     2135       False     40.3   \n",
       "4  C01          530374794       162  ...     2028        True     37.3   \n",
       "\n",
       "   AvgEvalOpening  AvgEvalMiddle  AvgEvalEnd  AvgEmtOpening  AvgEmtMiddle  \\\n",
       "0       15.571429      -7.461538    5.416667       0.126308      3.120000   \n",
       "1       30.340426      46.913043  104.086957       2.313957      3.352826   \n",
       "2       59.739130      58.186813 -216.551724       3.552725      0.891088   \n",
       "3      201.561404     500.696429  991.975610       2.761375      1.995554   \n",
       "4        7.000000    -108.166667 -410.115385       0.609074      0.589000   \n",
       "\n",
       "   AvgEmtEnd                   ResultComment  \n",
       "0   3.252667  Game drawn by mutual agreement  \n",
       "1   0.753348                   Black resigns  \n",
       "2   0.430033                   White resigns  \n",
       "3   0.277589                Black checkmated  \n",
       "4   0.436094                   White resigns  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df = combine_data_files('data-by-month')\n",
    "cleaned = clean_df_new(combined_df).dropna()\n",
    "print (cleaned.dtypes)\n",
    "print(cleaned.shape)\n",
    "cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_df_train(df):\n",
    "    # Define columns to take the average of and to one-hot encode\n",
    "    cols_to_avg = ['WhiteRD', 'BlackRD', 'AvgEvalOpening', 'AvgEvalMiddle', 'AvgEvalEnd', 'AvgEmtOpening', 'AvgEmtMiddle', 'AvgEmtEnd', 'PlyCount']\n",
    "    cols_to_onehot = ['ECO'] # 'White', 'Black',  <--- For if we decide to train using player UN for black and white as a features\n",
    "    ground_truth_labels = ['Result', 'ResultComment']\n",
    "\n",
    "    # Define dictionary to map column names to letters for one-hot encoding\n",
    "    col_name_to_letter = {col_name: chr(65+i) for i, col_name in enumerate(ground_truth_labels+cols_to_onehot)}\n",
    "\n",
    "    # Define column names for player-wise averages\n",
    "    new_cols_white = ['WhiteAvgRD', 'WhiteAvgEvalForOpenings', 'WhiteAvgEvalForMiddlegames', 'WhiteAvgEvalForEndgames', 'WhiteAvgEmtForOpenings', 'WhiteAvgEmtForMiddlegames', 'WhiteAvgEmtForEndgames', 'WhiteAvgPlyCount']\n",
    "    new_cols_black = ['BlackAvgRD', 'BlackAvgEvalForOpenings', 'BlackAvgEvalForMiddlegames', 'BlackAvgEvalForEndgames', 'BlackAvgEmtForOpenings', 'BlackAvgEmtForMiddlegames', 'BlackAvgEmtForEndgames', 'BlackAvgPlyCount']\n",
    "\n",
    "    # Compute player-wise averages\n",
    "    dataAvgsByUserWhite = {p: df[df['White'] == p][cols_to_avg+cols_to_onehot].mean(numeric_only=True) for p in df['White'].unique()}\n",
    "    dataAvgsByUserBlack = {p: df[df['Black'] == p][cols_to_avg+cols_to_onehot].mean(numeric_only=True) for p in df['Black'].unique()}\n",
    "\n",
    "    # Define empty dataframe to hold the new data\n",
    "    df_new = pd.DataFrame(columns = ground_truth_labels+cols_to_onehot+new_cols_white+new_cols_black)\n",
    "\n",
    "    # Iterate over each row in the original dataframe and create a new row in the output dataframe with the necessary data\n",
    "    for row in df.itertuples():\n",
    "        white_avg_values = dataAvgsByUserWhite.get(row.White, pd.Series([0]*len(cols_to_avg+cols_to_onehot)))\n",
    "        black_avg_values = dataAvgsByUserBlack.get(row.Black, pd.Series([0]*len(cols_to_avg+cols_to_onehot)))\n",
    "\n",
    "        white_new_cols = [white_avg_values[0], white_avg_values[2], white_avg_values[3], white_avg_values[4], white_avg_values[5], white_avg_values[6], white_avg_values[7], white_avg_values[8]]\n",
    "        black_new_cols = [black_avg_values[1], black_avg_values[2], black_avg_values[3], black_avg_values[4], black_avg_values[5], black_avg_values[6], black_avg_values[7], black_avg_values[8]]\n",
    "\n",
    "        new_row = tuple(getattr(row, label) for label in ground_truth_labels+cols_to_onehot) + tuple(white_new_cols) + tuple(black_new_cols)\n",
    "\n",
    "        df_new.loc[len(df_new)] = new_row\n",
    "\n",
    "    # One-hot encode the ground truth labels and cols_to_onehot\n",
    "    df_new = pd.get_dummies(df_new, columns = ground_truth_labels+cols_to_onehot, prefix = list(col_name_to_letter.values()))\n",
    "\n",
    "    # Map the column labels to their corresponding uppercase letters\n",
    "    df_new.columns = df_new.columns.map(lambda x: col_name_to_letter.get(x, x))\n",
    "\n",
    "    return df_new\n",
    "\n",
    "df_train = construct_df_train(cleaned).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WhiteAvgRD\n",
      "WhiteAvgEvalForOpenings\n",
      "WhiteAvgEvalForMiddlegames\n",
      "WhiteAvgEvalForEndgames\n",
      "WhiteAvgEmtForOpenings\n",
      "WhiteAvgEmtForMiddlegames\n",
      "WhiteAvgEmtForEndgames\n",
      "WhiteAvgPlyCount\n",
      "BlackAvgRD\n",
      "BlackAvgEvalForOpenings\n",
      "BlackAvgEvalForMiddlegames\n",
      "BlackAvgEvalForEndgames\n",
      "BlackAvgEmtForOpenings\n",
      "BlackAvgEmtForMiddlegames\n",
      "BlackAvgEmtForEndgames\n",
      "BlackAvgPlyCount\n",
      "A_Black\n",
      "A_Draw\n",
      "A_White\n",
      "B_Black checkmated\n",
      "B_Black forfeits by disconnection\n",
      "B_Black forfeits on time\n",
      "B_Black ran out of time and White has no material to mate\n",
      "B_Black resigns\n",
      "B_Black wins by adjudication\n",
      "B_Game drawn by mutual agreement\n",
      "B_Game drawn by repetition\n",
      "B_Game drawn by stalemate\n",
      "B_Game drawn by the 50 move rule\n",
      "B_Game drawn due to length\n",
      "B_Neither player has mating material\n",
      "B_White checkmated\n",
      "B_White forfeits by disconnection\n",
      "B_White forfeits on time\n",
      "B_White ran out of time and Black has no material to mate\n",
      "B_White resigns\n",
      "B_White wins by adjudication\n",
      "C_A00\n",
      "C_A01\n",
      "C_A02\n",
      "C_A03\n",
      "C_A04\n",
      "C_A05\n",
      "C_A06\n",
      "C_A07\n",
      "C_A08\n",
      "C_A09\n",
      "C_A10\n",
      "C_A11\n",
      "C_A12\n",
      "C_A13\n",
      "C_A14\n",
      "C_A15\n",
      "C_A16\n",
      "C_A17\n",
      "C_A18\n",
      "C_A19\n",
      "C_A20\n",
      "C_A21\n",
      "C_A22\n",
      "C_A23\n",
      "C_A24\n",
      "C_A25\n",
      "C_A26\n",
      "C_A27\n",
      "C_A28\n",
      "C_A29\n",
      "C_A30\n",
      "C_A31\n",
      "C_A32\n",
      "C_A33\n",
      "C_A34\n",
      "C_A35\n",
      "C_A36\n",
      "C_A37\n",
      "C_A38\n",
      "C_A39\n",
      "C_A40\n",
      "C_A41\n",
      "C_A42\n",
      "C_A43\n",
      "C_A44\n",
      "C_A45\n",
      "C_A46\n",
      "C_A47\n",
      "C_A48\n",
      "C_A49\n",
      "C_A50\n",
      "C_A51\n",
      "C_A52\n",
      "C_A53\n",
      "C_A54\n",
      "C_A55\n",
      "C_A56\n",
      "C_A57\n",
      "C_A58\n",
      "C_A59\n",
      "C_A60\n",
      "C_A61\n",
      "C_A62\n",
      "C_A63\n",
      "C_A64\n",
      "C_A65\n",
      "C_A66\n",
      "C_A67\n",
      "C_A68\n",
      "C_A69\n",
      "C_A70\n",
      "C_A71\n",
      "C_A72\n",
      "C_A73\n",
      "C_A74\n",
      "C_A75\n",
      "C_A76\n",
      "C_A77\n",
      "C_A78\n",
      "C_A79\n",
      "C_A80\n",
      "C_A81\n",
      "C_A82\n",
      "C_A83\n",
      "C_A84\n",
      "C_A85\n",
      "C_A86\n",
      "C_A87\n",
      "C_A88\n",
      "C_A89\n",
      "C_A90\n",
      "C_A91\n",
      "C_A92\n",
      "C_A93\n",
      "C_A95\n",
      "C_A96\n",
      "C_B00\n",
      "C_B01\n",
      "C_B02\n",
      "C_B03\n",
      "C_B04\n",
      "C_B05\n",
      "C_B06\n",
      "C_B07\n",
      "C_B08\n",
      "C_B09\n",
      "C_B10\n",
      "C_B11\n",
      "C_B12\n",
      "C_B13\n",
      "C_B14\n",
      "C_B15\n",
      "C_B16\n",
      "C_B17\n",
      "C_B18\n",
      "C_B19\n",
      "C_B20\n",
      "C_B21\n",
      "C_B22\n",
      "C_B23\n",
      "C_B24\n",
      "C_B25\n",
      "C_B26\n",
      "C_B27\n",
      "C_B28\n",
      "C_B29\n",
      "C_B30\n",
      "C_B31\n",
      "C_B32\n",
      "C_B33\n",
      "C_B34\n",
      "C_B35\n",
      "C_B36\n",
      "C_B37\n",
      "C_B38\n",
      "C_B39\n",
      "C_B40\n",
      "C_B41\n",
      "C_B42\n",
      "C_B43\n",
      "C_B44\n",
      "C_B45\n",
      "C_B46\n",
      "C_B47\n",
      "C_B48\n",
      "C_B49\n",
      "C_B50\n",
      "C_B51\n",
      "C_B52\n",
      "C_B53\n",
      "C_B54\n",
      "C_B55\n",
      "C_B56\n",
      "C_B57\n",
      "C_B58\n",
      "C_B59\n",
      "C_B60\n",
      "C_B61\n",
      "C_B62\n",
      "C_B63\n",
      "C_B64\n",
      "C_B65\n",
      "C_B66\n",
      "C_B67\n",
      "C_B68\n",
      "C_B69\n",
      "C_B70\n",
      "C_B71\n",
      "C_B72\n",
      "C_B73\n",
      "C_B74\n",
      "C_B75\n",
      "C_B76\n",
      "C_B77\n",
      "C_B78\n",
      "C_B79\n",
      "C_B80\n",
      "C_B81\n",
      "C_B82\n",
      "C_B83\n",
      "C_B84\n",
      "C_B85\n",
      "C_B86\n",
      "C_B87\n",
      "C_B88\n",
      "C_B89\n",
      "C_B90\n",
      "C_B91\n",
      "C_B92\n",
      "C_B93\n",
      "C_B94\n",
      "C_B95\n",
      "C_B96\n",
      "C_B97\n",
      "C_B98\n",
      "C_B99\n",
      "C_C00\n",
      "C_C01\n",
      "C_C02\n",
      "C_C03\n",
      "C_C04\n",
      "C_C05\n",
      "C_C06\n",
      "C_C07\n",
      "C_C08\n",
      "C_C09\n",
      "C_C10\n",
      "C_C11\n",
      "C_C12\n",
      "C_C13\n",
      "C_C14\n",
      "C_C15\n",
      "C_C16\n",
      "C_C17\n",
      "C_C18\n",
      "C_C19\n",
      "C_C20\n",
      "C_C21\n",
      "C_C22\n",
      "C_C23\n",
      "C_C24\n",
      "C_C25\n",
      "C_C26\n",
      "C_C27\n",
      "C_C28\n",
      "C_C29\n",
      "C_C30\n",
      "C_C31\n",
      "C_C32\n",
      "C_C33\n",
      "C_C34\n",
      "C_C35\n",
      "C_C36\n",
      "C_C37\n",
      "C_C38\n",
      "C_C39\n",
      "C_C40\n",
      "C_C41\n",
      "C_C42\n",
      "C_C43\n",
      "C_C44\n",
      "C_C45\n",
      "C_C46\n",
      "C_C47\n",
      "C_C48\n",
      "C_C49\n",
      "C_C50\n",
      "C_C51\n",
      "C_C52\n",
      "C_C53\n",
      "C_C54\n",
      "C_C55\n",
      "C_C56\n",
      "C_C57\n",
      "C_C58\n",
      "C_C59\n",
      "C_C60\n",
      "C_C61\n",
      "C_C62\n",
      "C_C63\n",
      "C_C64\n",
      "C_C65\n",
      "C_C66\n",
      "C_C67\n",
      "C_C68\n",
      "C_C69\n",
      "C_C70\n",
      "C_C71\n",
      "C_C72\n",
      "C_C73\n",
      "C_C74\n",
      "C_C75\n",
      "C_C76\n",
      "C_C77\n",
      "C_C78\n",
      "C_C79\n",
      "C_C80\n",
      "C_C81\n",
      "C_C82\n",
      "C_C83\n",
      "C_C84\n",
      "C_C85\n",
      "C_C86\n",
      "C_C87\n",
      "C_C88\n",
      "C_C89\n",
      "C_C90\n",
      "C_C91\n",
      "C_C92\n",
      "C_C93\n",
      "C_C94\n",
      "C_C95\n",
      "C_C96\n",
      "C_C97\n",
      "C_C99\n",
      "C_D00\n",
      "C_D01\n",
      "C_D02\n",
      "C_D03\n",
      "C_D04\n",
      "C_D05\n",
      "C_D06\n",
      "C_D07\n",
      "C_D08\n",
      "C_D09\n",
      "C_D10\n",
      "C_D11\n",
      "C_D12\n",
      "C_D13\n",
      "C_D14\n",
      "C_D15\n",
      "C_D16\n",
      "C_D17\n",
      "C_D18\n",
      "C_D19\n",
      "C_D20\n",
      "C_D21\n",
      "C_D22\n",
      "C_D23\n",
      "C_D24\n",
      "C_D25\n",
      "C_D26\n",
      "C_D27\n",
      "C_D28\n",
      "C_D29\n",
      "C_D30\n",
      "C_D31\n",
      "C_D32\n",
      "C_D33\n",
      "C_D34\n",
      "C_D35\n",
      "C_D36\n",
      "C_D37\n",
      "C_D38\n",
      "C_D39\n",
      "C_D40\n",
      "C_D41\n",
      "C_D42\n",
      "C_D43\n",
      "C_D44\n",
      "C_D45\n",
      "C_D46\n",
      "C_D47\n",
      "C_D48\n",
      "C_D49\n",
      "C_D50\n",
      "C_D51\n",
      "C_D52\n",
      "C_D53\n",
      "C_D54\n",
      "C_D55\n",
      "C_D56\n",
      "C_D58\n",
      "C_D59\n",
      "C_D60\n",
      "C_D61\n",
      "C_D63\n",
      "C_D64\n",
      "C_D65\n",
      "C_D66\n",
      "C_D67\n",
      "C_D70\n",
      "C_D71\n",
      "C_D73\n",
      "C_D74\n",
      "C_D76\n",
      "C_D77\n",
      "C_D78\n",
      "C_D79\n",
      "C_D80\n",
      "C_D81\n",
      "C_D82\n",
      "C_D83\n",
      "C_D85\n",
      "C_D86\n",
      "C_D87\n",
      "C_D88\n",
      "C_D89\n",
      "C_D90\n",
      "C_D91\n",
      "C_D92\n",
      "C_D93\n",
      "C_D94\n",
      "C_D95\n",
      "C_D96\n",
      "C_D97\n",
      "C_D99\n",
      "C_E00\n",
      "C_E01\n",
      "C_E02\n",
      "C_E03\n",
      "C_E04\n",
      "C_E05\n",
      "C_E06\n",
      "C_E07\n",
      "C_E08\n",
      "C_E09\n",
      "C_E10\n",
      "C_E11\n",
      "C_E12\n",
      "C_E13\n",
      "C_E14\n",
      "C_E15\n",
      "C_E16\n",
      "C_E17\n",
      "C_E18\n",
      "C_E19\n",
      "C_E20\n",
      "C_E21\n",
      "C_E22\n",
      "C_E23\n",
      "C_E24\n",
      "C_E25\n",
      "C_E26\n",
      "C_E27\n",
      "C_E28\n",
      "C_E29\n",
      "C_E30\n",
      "C_E31\n",
      "C_E32\n",
      "C_E33\n",
      "C_E34\n",
      "C_E35\n",
      "C_E36\n",
      "C_E37\n",
      "C_E38\n",
      "C_E39\n",
      "C_E40\n",
      "C_E41\n",
      "C_E42\n",
      "C_E43\n",
      "C_E44\n",
      "C_E45\n",
      "C_E46\n",
      "C_E47\n",
      "C_E48\n",
      "C_E49\n",
      "C_E50\n",
      "C_E51\n",
      "C_E52\n",
      "C_E53\n",
      "C_E54\n",
      "C_E55\n",
      "C_E56\n",
      "C_E57\n",
      "C_E58\n",
      "C_E59\n",
      "C_E60\n",
      "C_E61\n",
      "C_E62\n",
      "C_E63\n",
      "C_E64\n",
      "C_E65\n",
      "C_E66\n",
      "C_E67\n",
      "C_E68\n",
      "C_E69\n",
      "C_E70\n",
      "C_E71\n",
      "C_E72\n",
      "C_E73\n",
      "C_E75\n",
      "C_E76\n",
      "C_E77\n",
      "C_E79\n",
      "C_E80\n",
      "C_E81\n",
      "C_E82\n",
      "C_E83\n",
      "C_E85\n",
      "C_E87\n",
      "C_E88\n",
      "C_E90\n",
      "C_E91\n",
      "C_E92\n",
      "C_E93\n",
      "C_E94\n",
      "C_E95\n",
      "C_E96\n",
      "C_E97\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(25884, 517)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for x in df_train.columns:\n",
    "    print(x)\n",
    "\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25884 / 26032\n",
      "Data Loss : 0.57 %  \n",
      "(Mostly due to NaN eval scores. Try increasing engine computation time if this is too high.)\n"
     ]
    }
   ],
   "source": [
    "before = cleaned.shape[0]\n",
    "\n",
    "dropped = cleaned.dropna()\n",
    "\n",
    "after = dropped.shape[0]\n",
    "\n",
    "print ('{} / {}'.format(after,before))\n",
    "print ('Data Loss : {:.2f} %  \\n(Mostly due to NaN eval scores. Try increasing engine computation time if this is too high.)'.format(((before - after)*100)/before))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two types of ground truths in this dataset: a rudimentary outcome such as \"black won\" or \"game ended in a draw\", and a more specific description of the outcome such as \"black ran out of time\" or \"white checkmated\". The latter type of ground truth is very ambitious to predict as it is systemically very different; it requires great modeling of the problem to determine the precise result as opposed to a predictor that (more simply) needs to accurately guess the outcome. The random forest model formulates predictions based on the combination of many decision boundaries across different variables. It's unlikely that the inherent structure of the random forest is able to pick up on the nuances required to categorize among the more descriptive outcomes, so we will first focus on predicting the rudimentary outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedKFold, train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step, as with any machine learning process, is the split the data into useful training and test sets. We will do this using our `df_train` dataset, which is preprocessed with float64 and one-hot encoded features. This dataset still contains the ground truth labels as well, so we will drop them before splitting up our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all ground truth labels from the processed training data\n",
    "X = df_train.drop(columns=df_train.columns[df_train.columns.str.contains('A_') + df_train.columns.str.contains('B_') + df_train.columns.str.contains('C_')])\n",
    "# get the desired ground truth labels\n",
    "y = cleaned['Result']\n",
    "# split data for training and accuracy testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start off, we trained a very lax random forest model to guage our starting point. The only hyperparameter we changed is the number of estimators in the forest because we believed it would heavily influence the initial result. We did this using the grid search method, and the values were be selected with the intention of determining whether the optimal one is small or very large.\n",
    "\n",
    "Our initial fit of the random forest suggested that the optimal number of estimators is very large. Out of the list of hyperparameter values, the largest value `n_estimators=1000` produced the best predictive model with a test accuracy of about 70.9%. We later tried grid search with higher values of `n_estimators`, and the accuracy results were virtually the same. Consequently, we stuck with the value of `n_estimators=1000`.\n",
    "\n",
    "It's very common that random forests overfit the training data, so we checked whether we needed to prune our random forest by comparing the model performance on training data with the performance on test data. The model had a training accuracy of about 86.9%, which dominated the test accuracy of about 70.9%. Consequently, it seemed the model was overfit; it was much better at predicting from the training data than from the test data. \n",
    "\n",
    "We decided to try some pruning methods. The hyperparameter `ccp_alpha` helps with pruning, as induces selection of trees with the largest cost complexity that's less than this value. As this value increases, the number of nodes and the depth of trees both tend to decrease.\n",
    "\n",
    "After performing grid search on ccp_alpha, it was determined that the default value of `ccp_alpha=0` still produces the best performance for the model. This suggested that no pruning was necessary, but this contradicted our initial thoughts. After getting this result, we tried including other pruning variables: `max_depth`, `max_leaf_nodes`, and `min_sample_split`. After performing grid search with all these variables at once, we got the same result; the model performed the best with the default values. This implies that, despite overfitting, the model is better off without pruning.\n",
    "\n",
    "Finally, we also tried reducing some of the default variability among learners by eliminating the random feature selection during training, and this eliminated some of the overfitting. \n",
    "\n",
    "The training and test accuracies as a result of the hyperparameter selection process are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "# params = {'n_estimators':[100,200,500,1000], 'ccp_alpha': [0, 0.005, 0.01, 0.02], 'max_depth':[None,100,300,500], 'max_leaf_nodes':[None,100,200,300], 'min_sample_split':[None, 100, 300]}\n",
    "# rkf = RepeatedKFold(n_splits=5, n_repeats=5, random_state=42)\n",
    "# gs = GridSearchCV(RandomForestClassifier(n_jobs=-1), params, cv=rkf, n_jobs=-1)\n",
    "# gs.fit(X_train,y_train)\n",
    "\n",
    "# print('Best params: ', gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score using our best estimator:  0.8025034770514604\n",
      "Test score using our best estimator:  0.7168907433163344\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=1000, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "print('Training score using our best estimator: ', rf.score(X_train, y_train))\n",
    "print('Test score using our best estimator: ', rf.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
